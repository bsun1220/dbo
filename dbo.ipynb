{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9a54bae-3132-4737-81ee-c0090b81a839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from botorch.acquisition.acquisition import AcquisitionFunction\n",
    "from botorch.acquisition.objective import PosteriorTransform\n",
    "from botorch.exceptions import UnsupportedError\n",
    "from botorch.models.gp_regression import FixedNoiseGP\n",
    "from botorch.models.gpytorch import GPyTorchModel\n",
    "from botorch.models.model import Model\n",
    "from botorch.utils.constants import get_constants_like\n",
    "from botorch.utils.probability import MVNXPB\n",
    "from botorch.utils.probability.utils import (\n",
    "    log_ndtr as log_Phi,\n",
    "    log_phi,\n",
    "    log_prob_normal_in,\n",
    "    ndtr as Phi,\n",
    "    phi,\n",
    ")\n",
    "from botorch.utils.safe_math import log1mexp, logmeanexp\n",
    "from botorch.utils.transforms import convert_to_target_pre_hook, t_batch_mode_transform\n",
    "from torch import Tensor\n",
    "from torch.nn.functional import pad\n",
    "from botorch.test_functions import Hartmann, Ackley, Beale\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import ExpectedImprovement\n",
    "from botorch.acquisition.analytic import AnalyticAcquisitionFunction\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.test_functions import Hartmann\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.acquisition import qKnowledgeGradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "784152a0-cfc8-48f2-9470-f42262198de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiverseAcquisitionFunction(AnalyticAcquisitionFunction):\n",
    "    def __init__(self, model, lambda_, epsilon_, best_f):\n",
    "        super().__init__(model=model)\n",
    "        self.register_buffer(\"lambda_\", torch.as_tensor(lambda_))\n",
    "        self.register_buffer(\"epsilon_\", torch.as_tensor(epsilon_))\n",
    "        self.register_buffer(\"best_f\", torch.as_tensor(best_f))\n",
    "\n",
    "    @t_batch_mode_transform(expected_q = 1)\n",
    "    def forward(self, X: Tensor) -> Tensor:\n",
    "        mean, sigma = self._mean_and_sigma(X)\n",
    "        factor = (1 + self.epsilon_ ) if self.best_f > 0 else (1 - epsilon_)\n",
    "        \n",
    "        ei_portion = Phi((self.best_f - mean)/sigma) * (self.best_f - mean)\n",
    "        dei_portion = phi((self.best_f - mean)/sigma) + self.lambda_ * Phi((factor * self.best_f - mean)/sigma)\n",
    "        \n",
    "        return ei_portion + dei_portion * sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ab7699d-279e-48b2-a740-409cffb875d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from botorch.test_functions import Hartmann, Ackley, Beale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d21f1c29-3bc3-477f-a23d-7aab97ea47a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hartmann Function\n",
    "num_start = 100\n",
    "bounds = torch.tensor([[0.0] * 6, [1.0] * 6])\n",
    "func = Hartmann(dim=6, negate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e68fb291-6826-4c1a-96fa-921c5bde55fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ackley Function\n",
    "dim = 2\n",
    "num_start = 100\n",
    "bounds = torch.tensor([[-32.0] * 2, [32.0] * 2])\n",
    "func = Ackley(dim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e5c3d6b4-11d2-402b-b500-534e4048925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beale Function\n",
    "num_start = 100\n",
    "bounds = torch.tensor([[-32.0] * 2, [32.0] * 2])\n",
    "func = Beale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dcda3b54-d7bf-4cee-a7eb-7cec84286821",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lambda_ = 0.5\n",
    "epsilon_ = 0.05\n",
    "DEI_param_settings = {\"lambda_\":lambda_, \"epsilon_\":epsilon_}\n",
    "EI_param_settings = {\"maximize\":False}\n",
    "know_param_settings = {\"num_fantasies\":50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1cdb8520-07ed-4e75-81f0-a276f93f4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scalarize_input(train_x, bounds):\n",
    "    train_x_i = torch.clone(train_x)\n",
    "    for dim in range(bounds.shape[1]):\n",
    "        bound = bounds[:, dim]\n",
    "        train_x_i[:, dim] -= bound[0]\n",
    "        train_x_i[:, dim] /= ((bound[1] - bound[0]))\n",
    "    return train_x_i\n",
    "\n",
    "def revert_input(train_x_i, bounds):\n",
    "    train_x = torch.clone(train_x_i)\n",
    "    for dim in range(bounds.shape[1]):\n",
    "        bound = bounds[:, dim]\n",
    "        train_x[:, dim] *= ((bound[1] - bound[0]))\n",
    "        train_x[:, dim] += bound[0]\n",
    "    return train_x\n",
    "    \n",
    "def scalarize_output(train_obj):\n",
    "    mean = train_obj.mean()\n",
    "    std = train_obj.std()\n",
    "    return (train_obj - mean)/std, mean, std\n",
    "\n",
    "def revert_output(train_obj, mean, std):\n",
    "    return train_obj * std + mean\n",
    "    \n",
    "def bayes_opt_loop(opt_func, bounds, num_start, num_sim, acf_func, param_settings = {}):\n",
    "    dim = bounds.shape[1]\n",
    "    \n",
    "    #actual observed \n",
    "    obs_x = revert_input(torch.rand(num_start, dim), bounds)\n",
    "    obs_obj = opt_func(obs_x).unsqueeze(-1)\n",
    "    \n",
    "    #regularized inputs to model\n",
    "    model_bounds = torch.tensor([[0.0] * dim, [1.0] * dim])\n",
    "    model_input = scalarize_input(obs_x, bounds)\n",
    "    model_output, mean, sigma = scalarize_output(obs_obj)\n",
    "    var = torch.zeros(model_output.shape) + 10**(-6)\n",
    "\n",
    "    model = FixedNoiseGP(train_X = model_input, train_Y = model_output, train_Yvar = var)\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_mll(mll)\n",
    "\n",
    "    acf_func = acf_func(model = model, best_f = model_output.min(), **param_settings)\n",
    "\n",
    "    for i in range(num_sim):\n",
    "        best_f = model_output.min()\n",
    "        acf_func.model = model\n",
    "        acf_func.best_f = best_f\n",
    "        \n",
    "        new_point, _ = optimize_acqf(acf_func, bounds=model_bounds, q = 1, num_restarts = 5, raw_samples = 100)\n",
    "        eval_point = revert_input(new_point, bounds)\n",
    "        eval_result = opt_func(eval_point).expand(1, 1)\n",
    "        reg_eval_result = (eval_result - mean)/sigma\n",
    "        \n",
    "        model_input = torch.cat((model_input, new_point), 0)\n",
    "        model_output = torch.cat((model_output, reg_eval_result), 0)\n",
    "        var = torch.cat((var, torch.as_tensor(10**-6).expand(1,1)), 0)\n",
    "        \n",
    "        #rechange parameters for output\n",
    "        if i % 10 == 0:\n",
    "            model_output = revert_output(model_output, mean, sigma)\n",
    "            model_output, mean, sigma = scalarize_output(model_output)\n",
    "        \n",
    "        model = FixedNoiseGP(train_X = model_input, train_Y = model_output, train_Yvar = var)\n",
    "        mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "        fit_gpytorch_mll(mll)\n",
    "    \n",
    "    obs_x = revert_input(model_input, bounds)\n",
    "    obs_obj = revert_output(model_output, mean, sigma)\n",
    "    return obs_x, obs_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1708dd-8099-43e5-a5f8-11991cf66bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bayes_opt_loop(func, bounds, 100, 1000, ExpectedImprovement, EI_param_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bd4f1ba9-73c3-40db-94e0-a40b5894c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = bayes_opt_loop(func, bounds, 100, 1000, DiverseAcquisitionFunction, DEI_param_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9a26464d-33a2-4317-91bf-b65caa43de83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = bayes_opt_loop(func, bounds, 100, 10, qKnowledgeGradient, know_param_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "bd2370c7-457f-448f-b393-5b6835bba5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(true_min, train_obj, train_x, epsilon_):\n",
    "    factor = (1 + epsilon_) if true_min > 0 else (1 - epsilon_)\n",
    "\n",
    "    torch_ind = train_obj < factor * true_min\n",
    "    ind = []\n",
    "    i = 0\n",
    "    for val in torch_ind:\n",
    "        if val:\n",
    "            ind.append(i)\n",
    "        i += 1\n",
    "\n",
    "    feasible_sol, feasible_x = train_obj[ind], train_x[ind]\n",
    "    max_dist = 0 \n",
    "\n",
    "    for i in range(feasible_sol.shape[0]):\n",
    "        for j in range(i + 1, feasible_sol.shape[0]):\n",
    "            val1, val2 = feasible_x[i], feasible_x[j]\n",
    "            max_dist = max(max_dist, torch.norm(val1 - val2))\n",
    "\n",
    "    return feasible_sol, feasible_x, max_dist.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cc25c7-67b5-4635-ac4e-2926f3956c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(0.4, y, x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130232a2-8855-4b4e-983f-ccdc085cc256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
